====================================================================
  LANGCHAIN RAG SYSTEM - SETUP AND RUN INSTRUCTIONS
====================================================================

This document explains how to run the standalone langchain RAG system
(non-ROS2 version) located in the 'langchain' directory.

--------------------------------------------------------------------
PREREQUISITES
--------------------------------------------------------------------

1. Python 3.10 or higher installed
2. Redis server running (required for caching)
3. OpenAI API key

--------------------------------------------------------------------
DIRECTORY STRUCTURE
--------------------------------------------------------------------

langchain/
├── main.py           # Main RAG application
├── caching.py        # Redis caching implementation
├── test.py           # Test file (if needed)
├── knowledge1.pdf    # First knowledge base PDF
├── knowledge2.pdf    # Second knowledge base PDF
└── .env              # Environment variables (create this)

--------------------------------------------------------------------
STEP 1: INSTALL DEPENDENCIES
--------------------------------------------------------------------

Install the required Python packages:

pip install langchain langchain-openai langchain-community langchain-chroma langchain-text-splitters
pip install python-dotenv redis chromadb pypdf pydantic

--------------------------------------------------------------------
STEP 2: SET UP ENVIRONMENT VARIABLES
--------------------------------------------------------------------

Create a .env file in the 'langchain' directory with the following:

OPENAI_API_KEY=your_openai_api_key_here
REDIS_URL=redis://localhost:6379

Replace 'your_openai_api_key_here' with your actual OpenAI API key.

--------------------------------------------------------------------
STEP 3: START REDIS SERVER
--------------------------------------------------------------------

Before running the application, make sure Redis is running:

On Windows (if Redis is installed):
  redis-server

On Linux/Mac:
  redis-server

Or using Docker:
  docker run -d -p 6379:6379 redis:latest

--------------------------------------------------------------------
STEP 4: PREPARE PDF FILES
--------------------------------------------------------------------

Ensure you have two PDF files in the langchain directory:
- knowledge1.pdf (contains information about "El Inmortal" character)
- knowledge2.pdf (contains information about Reflex products/inventory)

--------------------------------------------------------------------
STEP 5: RUN THE APPLICATION
--------------------------------------------------------------------

Navigate to the langchain directory:
  cd langchain

Run the main script:
  python main.py

--------------------------------------------------------------------
USAGE
--------------------------------------------------------------------

When you run main.py:

1. The system will initialize and load the PDF documents
2. It will create vector stores (chroma_knowledge1_db and chroma_knowledge2_db)
   - First run: Creates the vector databases (may take a few minutes)
   - Subsequent runs: Uses existing vector databases (faster)
3. You'll be prompted: "Whats your question?: "
4. Type your question and press Enter
5. The system will:
   - Check cache for previous answers
   - Analyze the question type
   - Route to appropriate vector store or skill
   - Return the answer

--------------------------------------------------------------------
FEATURES
--------------------------------------------------------------------

The system includes:
- Dual vector stores for different knowledge domains
- BM25 + Vector hybrid retrieval
- Redis caching for Q&A pairs and embeddings
- LLM caching for faster responses
- Document relevance grading
- Static skills (current time/date)
- Intelligent routing between vector stores

--------------------------------------------------------------------
VECTOR STORE ROUTING
--------------------------------------------------------------------

Vector Store 1 (knowledge1.pdf):
- Information about "El Inmortal" character
- Author information (Luis Alvaro Rosales Salazar)

Vector Store 2 (knowledge2.pdf):
- Reflex company products
- Construction goods and inventory

The system automatically routes questions to the appropriate store.

--------------------------------------------------------------------
CACHING
--------------------------------------------------------------------

The system uses Redis for multiple layers of caching:
1. LLM response caching (via langchain RedisCache)
2. Embeddings caching (via CacheBackedEmbeddings)
3. Q&A pair caching (custom implementation)
   - Max 10,000 cached Q&A pairs
   - Automatic eviction when capacity reached

--------------------------------------------------------------------
TROUBLESHOOTING
--------------------------------------------------------------------

Issue: "Redis connection failed"
Solution: Make sure Redis server is running on localhost:6379

Issue: "cannot import name 'CacheBackedEmbeddings'"
Solution: Ensure you have the correct import in caching.py:
  from langchain.embeddings import CacheBackedEmbeddings

Issue: "File not found" for PDFs
Solution: Place knowledge1.pdf and knowledge2.pdf in the langchain directory

Issue: OpenAI API errors
Solution: Check that your OPENAI_API_KEY is set correctly in .env

Issue: First run is slow
Solution: This is normal - the system is creating vector embeddings
  Subsequent runs will be much faster.

--------------------------------------------------------------------
STOPPING THE APPLICATION
--------------------------------------------------------------------

To exit the program:
- Press Ctrl+C in the terminal

To clear cached data (if needed):
- Delete the chroma_knowledge1_db and chroma_knowledge2_db directories
- Use Redis CLI to clear cache: redis-cli FLUSHALL

--------------------------------------------------------------------
EXAMPLE QUESTIONS
--------------------------------------------------------------------

For Vector Store 1 (El Inmortal):
- "Tell me about El Inmortal"
- "Who is Luis Alvaro Rosales Salazar?"

For Vector Store 2 (Reflex):
- "What products does Reflex sell?"
- "Tell me about construction glue"

For Static Skills:
- "What time is it?"
- "What is today's date?"

For General LLM:
- "What is the capital of France?"
- "Explain quantum computing"

====================================================================
