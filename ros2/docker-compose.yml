version: '3.8'

services:
  # Redis service for caching
  redis:
    image: redis:7-alpine
    container_name: rag_redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5
    networks:
      - rag_network

  # Ollama service for local LLM (COMMENTED OUT - NOW USING CHATGPT/OPENAI)
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: rag_ollama
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ollama_data:/root/.ollama
  #   networks:
  #     - rag_network
  #   healthcheck:
  #     test: ["CMD", "ollama", "list"]
  #     interval: 10s
  #     timeout: 5s
  #     retries: 5
  #     start_period: 10s

  # ROS2 RAG Service
  rag_service:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: rag_service_node
    depends_on:
      redis:
        condition: service_healthy
      # ollama:  # COMMENTED OUT - NOW USING CHATGPT/OPENAI
      #   condition: service_healthy
    environment:
      # OLLAMA CONFIGURATION (COMMENTED OUT - NOW USING CHATGPT/OPENAI)
      # - OLLAMA_BASE_URL=http://ollama:11434
      # - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3.1:8b}
      - OPENAI_API_KEY=${OPENAI_API_KEY}  # ChatGPT/OpenAI API Key
      - REDIS_URL=redis://redis:6379
      - ROS_DOMAIN_ID=${ROS_DOMAIN_ID:-0}
    volumes:
      # Mount the package sources for development (optional)
      - ./rag_interfaces:/ros2_ws/src/rag_interfaces
      - ./rag_service:/ros2_ws/src/rag_service
      # Persist vector databases
      - vector_dbs:/ros2_ws/src/rag_service/data/vector_dbs
    networks:
      - rag_network
    stdin_open: true
    tty: true
    command: ros2 launch rag_service rag_service_launch.py

  # Optional: Example client for testing
  rag_client:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: rag_client
    depends_on:
      - rag_service
    environment:
      - ROS_DOMAIN_ID=0
    networks:
      - rag_network
    stdin_open: true
    tty: true
    command: ros2 run rag_service rag_client_example
    profiles:
      - client  # Only start with: docker-compose --profile client up

volumes:
  redis_data:
    driver: local
  vector_dbs:
    driver: local
  # ollama_data:  # COMMENTED OUT - NOW USING CHATGPT/OPENAI
  #   driver: local

networks:
  rag_network:
    driver: bridge
